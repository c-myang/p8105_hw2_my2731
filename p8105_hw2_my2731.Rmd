---
title: "P8105 Homework 2"
output: github_document
date: "October 5th, 2022"
---

```{r setup, include = FALSE}
library(tidyverse)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## Problem 1: NYC Transit Data

### Cleaning the data

We will work with NYC Transit data; which contains information related to each entrance and exit for each subway station in NYC. 

We will read in and clean the data by retaining line, station name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. We also want to convert the entry variable from character (YES vs NO) to a logical variable. 

To achieve this, we will read in the dataset using `read_csv()`, convert the variable names to snake case using `janitor::clean_names()`, use `select()` to keep the variables of interest in our data, then use `mutate()` and `recode()` to convert the `entry` from a character to a logical variable.

```{r clean_data}
transit_data = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, YES = TRUE, NO = FALSE)) 

transit_data
```

We can see our cleaned data includes `r ncol(transit_data)` variables and `r nrow(transit_data)` observations. For each station entrance/exit, we have information about the station name, line, the station latitude and longitude, the routes it serves, entrance type, whether it has an entry, has a ticket vendor, and whether it is ADA-compliant.

After these steps, these data are not fully tidy. We can see there are several `route#` columns to indicate each individual subway route a station serves, making our dataset very wide. Moreover, the `vending` variable is in a character format, and could be converted to a logical variable, since it is a binary variable (like `entry` and `ada`).

### Data Exploration
Next, we will explore a few aspects of our data.
Using `distinct()`, we can get the number of unique stations, accounting for stations with the same name along different lines . 

```{r distinct}
distinct(transit_data, line, station_name) %>% 
  arrange(station_name)
```
Arranging the data by station name, we can see the output gave us entries for each unique combination of station name and line.

In total, there are **`r nrow(distinct(transit_data, line, station_name))` unique stations**.

Next, we want to know how many stations are ADA-compliant. For this, we can use `group_by` and `summarise` to get the frequency of `TRUE`'s under the `ada` variable.

```{r adacomp}
transit_data %>%
  distinct(line, station_name, .keep_all = TRUE) %>% 
  group_by(ada) %>%
  summarise(n = n())
```

From our results, we can see that **84 stations are ADA-compliant.**

Next, we want to know what proportion of entrances/exits without vending allow entrance. For this, we will `filter` observations to those with `vending == "NO"`, then use `group_by`, `summarise`, and `mutate` to compute the proportion of entrances/exits with `entry == "YES"`.

```{r prop_entry}
transit_data %>%
  filter(vending == "NO") %>% 
  group_by(entry) %>%
  summarise(n = n()) %>%
  mutate(prop = n / sum(n))
```
From our results, **37.71% of station entrances / exits without vending allow entry.**

Finally, we want to know how many stations serve the A and are ADA-compliant. We will use `pivot_longer` to reformat data so that route number and route name are distinct variables. To do this, we must first mutate all `route#` variables into a character format so `pivot_longer` can be used. 

Then, we will filter the dataset to only stations that serve `route_name == "A"`, and use `distinct` to get a list of unique stations.

```{r reformat}
A_stations = transit_data %>% 
  mutate(route8 = as.character(route8), 
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11)) %>% 
  pivot_longer(
    route1:route11, 
    names_to = "route_number", 
    values_to = "route_name", 
    names_prefix = "route"
  ) %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name, .keep_all = TRUE)

A_stations
```

Our results returned a subset of the `transit_data` with a unique combination of line and station name, filtered to the A line. There are 10 variables and 60 observations in our A_stations dataset, indicating **60** unique stations that serve the A line.

```{r a_ada}
A_stations %>% 
  group_by(ada) %>% 
  summarise(n = n()) %>%
  mutate(prop = n / sum(n))
```
Finally, grouping the `A_stations` dataset by `ada` status, and summarizing the results, we can see that **17 of the 60 (28.3%) stations that serve the A are ADA-compliant.**

## Problem 2: Mr. Trash Wheel Data
### Reading and cleaning data
First, we will read and clean the Mr. Trash Wheel sheet from the Trash Wheel Collection Totals Excel file in `./data` folder. We will convert variable names to snake case, round the `sports_balls` variable to an integer, and convert the `year` variable to a numeric variable. Finally, we will add a `vessel` variable to label all observations in the data as coming from Mr. Trash Wheel sheet.

```{r}
mrtrash_wheel = 
  readxl::read_excel("./data/Trash Wheel Collection Data.xlsx",
                     sheet = "Mr. Trash Wheel",
                     range = "A2:N549") %>% 
  janitor::clean_names() %>% 
  mutate(sports_balls = as.integer(sports_balls)) %>% 
  mutate(year = as.numeric(year)) %>% 
  mutate(vessel = "Mr. Trash Wheel")
```

Next, we will repeat the same reading and cleaning processes in the Professor Trash Wheel sheet, in the same Excel file. Similarly, we will add a `vessel` variable to label all observations in the data as coming from Professor Trash Wheel sheet.

```{r}
proftrash_wheel = 
  readxl::read_excel("./data/Trash Wheel Collection Data.xlsx",
                     sheet = "Professor Trash Wheel",
                     range = "A2:M96") %>% 
  janitor::clean_names() %>% 
  mutate(vessel = "Professor Trash Wheel")
```

Finally, we can bind the Mr. Trash Wheel and Professor Trash Wheel data into a single tidy dataset. We can distinguish which observation comes from which sheet using the `vessel` variable in column 1.

```{r}
trash_wheel = 
  bind_rows(mrtrash_wheel, proftrash_wheel) %>% 
  relocate(vessel)
```

### Describing the  `trash_wheel` dataset

```{r}
trash_wheel
```

In our tidied dataset, we have a tibble containing **`r nrow(trash_wheel)` observations** and **`r ncol(trash_wheel)` variables**. The variables in the dataset describe several characteristics of each dumpster collected from either the Mr. Trash or Professor Trash Wheel. It includes identifiers like the dumpster number and date, and vessel it originates from. It also describes the weight (in tons) and volume (in cubic yards) of trash collected, as well as counts of common types of trash found in the dumpster, such as plastic bottles, polystyrene, cigarette butts, and sports balls.

Using `summarise`, we can answer some questions about our data. 

```{r}
total_weight = trash_wheel %>% 
  filter(vessel == "Professor Trash Wheel") %>% 
  summarise(n = sum(weight_tons))

total_sports_balls = trash_wheel %>% 
  filter(vessel == "Mr. Trash Wheel", year == 2020) %>% 
  summarise(n = sum(sports_balls))
```

The total weight of trash collected by Professor Trash Wheel is **`r total_weight` tons.**

The total number of sports balls collected by Mr. Trash Wheel in 2020 was **`r total_sports_balls`.**

## Problem 3: FiveThirtyEight Data
### Reading and cleaning data

First, we will clean the `pols-month.csv` data. 

We'll use `separate()` to break up the variable `mon` into integer variables year, month, and day. Then, we use `month.name` within the `mutate` function to replace month number with month name. To ensure consistency across datasets, we will use `as.numeric()` to convert `year` to a numeric variable. Then, we'll use `ifelse` to create a president variable taking values `gop` and `dem`, and use `select` to remove `prez_dem`, `prez_gop`, and the `day` variable. 

```{r pols}
pols_month = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(month = month.name[as.numeric(month)]) %>%
  mutate(year = as.numeric(year)) %>% 
  mutate(president = ifelse(prez_dem == 1, "dem", "rep")) %>% 
  select(-prez_dem, -prez_gop, -day)

pols_month
```

Second, we will clean the data in `snp.csv` using a similar process as above. To ensure consistency across datasets, we will set `year` as a numeric variable and insert prefixes of `19` or `20` such that year is a 4-digit format. 

```{r snp}
snp = read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), sep = "/") %>% 
  mutate(month = month.name[as.numeric(month)]) %>% 
  mutate(year = as.numeric(ifelse(year > 15, paste0("19", year), paste0("20", year)))) %>% 
  select(-day) %>% 
  relocate(year)

snp
```

Third, we will tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name, and ensuring that key variables take the same values. Particularly, we will match the month abbreviations to month names such that month is a character string for the full name of the month, like in `snp` and `pols_month`.

```{r unemployment}
unemployment = read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "pct_unemployed") %>% 
  mutate(month = month.name[match(str_to_title(month), month.abb)])

unemployment
```

Finally, we will join the datasets by merging `snp` into `pols_month`, and merging `unemployment` into the final dataset, `five_thirty_eight`.

```{r join}
five_thirty_eight = 
  left_join(pols_month, snp, by = c("month", "year")) %>% 
  left_join(unemployment, by = c("month", "year"))
```

### Describing the data

The dataset `pols-month` contains 822 observations of 9 variables related to the number of national politicians who are democratic or republican for each month between January 1947 and June 2015. It includes counts of Democratic or Republican governors, Senators, and Congressional representatives, as well as `president`, which indicates whether the President at the time was Democratic or Republican.

The dataset `snp` contains 787 observations of 3 variables. Its main variable is `closing`, which is the closing price of Standard & Poor’s stock market index (S&P), often used as a representative measure of stock market as a whole, for each month between January 1950 and July 2015. 

The dataset `unemployment` contains 816 observations of 3 variables. Its main variable is `pct_unemployed`, which is the unemployment rate for each month between January 1948 and December 2015.

```{r}
five_thirty_eight
```

Joined together, the final `five_thirty_eight` dataset merges information from the 3 prior datasets in a table of 11 variables and 822 observations. It contains information about the counts of national politicians along party lines, closing prices of the S&P index, and unemployment rate for each month between 1947 and 2015.

