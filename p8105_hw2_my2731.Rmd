---
title: "P8105 Homework 2"
output: github_document
date: "October 5th, 2022"
---

```{r setup, include = FALSE}
library(tidyverse)
```

## Problem 1: NYC Transit Data

### Cleaning the data

We will work with NYC Transit data; which contains information related to each entrance and exit for each subway station in NYC. 

We will read in and clean the data by retaining line, station name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. We also want to convert the entry variable from character (YES vs NO) to a logical variable. 

To achieve this, we will read in the dataset using `read_csv()`, convert the variable names to snake case using `janitor::clean_names()`, use `select()` to keep the variables of interest in our data, then use `mutate()` and `recode()` to convert the `entry` from a character to a logical variable.

```{r clean_data, warning = FALSE, message = FALSE}
transit_data = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, YES = TRUE, NO = FALSE)) 

head(transit_data)
```

Using `head(transit_data)`, we can see our cleaned data includes 19 variables and 1868 observations. For each station entrance/exit, we have information about the station name, line, the station latitude and longitude, the routes it serves, entrance type, whether it has an entry, has a ticket vendor, and whether it is ADA compliant.

After these steps, these data are not fully tidy. We can see there are several `route#` columns to indicate each individual subway route a station serves, making our dataset very wide. Moreover, the `vending` variable could also be converted to a logical variable, since it is a binary variable (like `entry` and `ada`).

### Data Exploration
Next, we will explore a few aspects of our data.
Using `distinct()`, we can get the number of unique stations, accounting for stations with the same name along different lines . 

```{r}
distinct(transit_data, line, station_name) %>% 
  arrange(station_name)
```
Arranging the data by station name, we can see the output gave us entries for each unique combination of station name and line.

In total, there are **`r nrow(distinct(transit_data, line, station_name))` unique stations**.

Next, we want to know how many stations are ADA compliant. For this, we can use `group_by` and `summarise` to get the frequency of `TRUE`'s under the `ada` variable.

```{r}
transit_data %>%
  distinct(line, station_name, ada) %>% 
  group_by(ada) %>%
  summarise(n = n())
```

From our results, we can see that **84 stations are ADA-compliant.**

Finally, we want to know what proportion of entrances/exits without vending allow entrance. For this, we will `filter` observations to those with `vending == "NO"`, then use `group_by`, `summarise`, and `mutate` to compute the proportion of entrances/exits with `entry == "YES"`.

```{r}
transit_data %>%
  filter(vending == "NO") %>% 
  group_by(entry) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n))
```
From our results, **37.71% of station entrances / exits without vending allow entry.**


## Problem 2: Mr. Trash Wheel Data
### Reading and cleaning data
First, we will read and clean the Mr. Trash Wheel sheet from the Trash Wheel Collection Totals Excel file in `./data` folder. We will convert variable names to snake case, filter out observations without a dumpster number (to remove rows without dumpster-specific data), round the `sports_balls` variable to an integer, and add a `vessel` variable to label all observations in the data as coming from Mr. Trash Wheel sheet.

```{r}
mrtrash_wheel = 
  readxl::read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
                     sheet = "Mr. Trash Wheel",
                     range = "A2:N534") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(sports_balls)) %>% 
  mutate(vessel = "Mr. Trash Wheel")
```

Next, we will repeat the same reading and cleaning processes in the Professor Trash Wheel sheet, in the same Excel file. Similarly, we will add a `vessel` variable to label all observations in the data as coming from Professor Trash Wheel sheet.

```{r}
proftrash_wheel = 
  readxl::read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
                     sheet = "Professor Trash Wheel",
                     range = "A2:N116") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(sports_balls)) %>% 
  mutate(vessel = "Professor Trash Wheel")
```

Finally, we can bind the Mr. Trash Wheel and Professor Trash Wheel data into a single tidy dataset. We can distinguish which observation comes from which sheet using the `vessel` variable in column 1.

```{r}
trash_wheel = 
  bind_rows(mrtrash_wheel, proftrash_wheel) %>% 
  relocate(vessel)
```
### Describing the  `trash_wheel` dataset

```{r}
skimr::skim(trash_wheel)
```

In our tidied dataset, we have a tibble containing 15 variables and 524 observations. The variables in the dataset describe several characteristics of each dumpster collected from either the Mr. Trash or Professor Trash Wheel. It includes identifiers like the dumpster number and date, and vessel it originates from. It also describes the weight (in tons) and volume (in cubic yards) of trash collected, as well as counts of common types of trash found in the dumpster, such as plastic bottles, polystyrene, cigarette butts, and sports balls.

Using `summarise`, we can answer some questions about our data. 

```{r}
total_weight = trash_wheel %>% 
  filter(vessel == "Professor Trash Wheel") %>% 
  summarise(n = sum(weight_tons))

total_sports_balls = trash_wheel %>% 
  filter(vessel == "Mr. Trash Wheel", year == 2020) %>% 
  summarise(n = sum(sports_balls))
```

The total weight of trash collected by Professor Trash Wheel is **`r total_weight` tons.**

The total number of sports balls collected by Mr. Trash Wheel in 2020 was **`r total_sports_balls`.**

## Problem 3: FiveThirtyEight Data
### Reading and cleaning data

First, we will clean the `pols-month.csv` data. 

We'll use `separate()` to break up the variable `mon` into integer variables year, month, and day. Then, we use `month.name` within the `mutate` function to replace month number with month name. Then, we'll use `ifelse` to create a president variable taking values `gop` and `dem`, and use `select` to remove `prez_dem`, `prez_gop`, and the `day` variable.

```{r pols, message = FALSE}
pols_month = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(month = month.name[as.numeric(month)]) %>%
  mutate(year = as.numeric(year)) %>% 
  mutate(president = ifelse(prez_dem == 1, "dem", "rep")) %>% 
  select(-prez_dem, -prez_gop, -day)
```

Second, we will clean the data in `snp.csv` using a similar process as above. 

```{r snp, message = FALSE}
snp = read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), sep = "/") %>% 
  mutate(month = month.name[as.numeric(month)]) %>% 
  mutate(year = as.numeric(ifelse(year > 15, paste0("19", year), paste0("20", year)))) %>% 
  select(-day) %>% 
  relocate(year)
```

Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r unemployment, message = FALSE}
unemployment = read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "pct_unemployed") %>% 
  mutate(month = month.name[match(str_to_title(month), month.abb)])
```

Finally, we will join the datasets by merging snp into pols, and merging unemployment into the result.

```{r join, message = FALSE}
five_thirty_eight = 
  left_join(pols_month, snp, by = c("month", "year")) %>% 
  left_join(unemployment, by = c("month", "year"))
```

The file “pols-month” contains 822 observations of 9 variables related to the number of national politicians who are democratic or republican at any given time:

The file “snp” contains 787 observations of 2 variables related to Standard & Poor’s stock market index (S&P), often used as a representative measure of stock market as a whole:

The file “unemployment” contains 68 observations of 13 variables:

