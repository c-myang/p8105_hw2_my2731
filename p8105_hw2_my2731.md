P8105 Homework 2
================
October 5th, 2022

## Problem 1: NYC Transit Data

### Cleaning the data

We will work with NYC Transit data; which contains information related
to each entrance and exit for each subway station in NYC.

We will read in and clean the data by retaining line, station name,
station latitude / longitude, routes served, entry, vending, entrance
type, and ADA compliance. We also want to convert the entry variable
from character (YES vs NO) to a logical variable.

To achieve this, we will read in the dataset using `read_csv()`, convert
the variable names to snake case using `janitor::clean_names()`, use
`select()` to keep the variables of interest in our data, then use
`mutate()` and `recode()` to convert the `entry` from a character to a
logical variable.

``` r
transit_data = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, YES = TRUE, NO = FALSE)) 

transit_data
```

    ## # A tibble: 1,868 × 19
    ##    line     station_…¹ stati…² stati…³ route1 route2 route3 route4 route5 route6
    ##    <chr>    <chr>        <dbl>   <dbl> <chr>  <chr>  <chr>  <chr>  <chr>  <chr> 
    ##  1 4 Avenue 25th St       40.7   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  2 4 Avenue 25th St       40.7   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  3 4 Avenue 36th St       40.7   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ##  4 4 Avenue 36th St       40.7   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ##  5 4 Avenue 36th St       40.7   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ##  6 4 Avenue 45th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  7 4 Avenue 45th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  8 4 Avenue 45th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  9 4 Avenue 45th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ## 10 4 Avenue 53rd St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ## # … with 1,858 more rows, 9 more variables: route7 <chr>, route8 <dbl>,
    ## #   route9 <dbl>, route10 <dbl>, route11 <dbl>, entrance_type <chr>,
    ## #   entry <lgl>, vending <chr>, ada <lgl>, and abbreviated variable names
    ## #   ¹​station_name, ²​station_latitude, ³​station_longitude

We can see our cleaned data includes 19 variables and 1868 observations.
For each station entrance/exit, we have information about the station
name, line, the station latitude and longitude, the routes it serves,
entrance type, whether it has an entry, has a ticket vendor, and whether
it is ADA-compliant.

After these steps, these data are not fully tidy. We can see there are
several `route#` columns to indicate each individual subway route a
station serves, making our dataset very wide. Moreover, the `vending`
variable is in a character format, and could be converted to a logical
variable, since it is a binary variable (like `entry` and `ada`).

### Data Exploration

Next, we will explore a few aspects of our data. Using `distinct()`, we
can get the number of unique stations, accounting for stations with the
same name along different lines .

``` r
distinct(transit_data, line, station_name) %>% 
  arrange(station_name)
```

    ## # A tibble: 465 × 2
    ##    line             station_name               
    ##    <chr>            <chr>                      
    ##  1 8 Avenue         103rd St                   
    ##  2 Broadway-7th Ave 103rd St                   
    ##  3 Flushing         103rd St                   
    ##  4 Lexington        103rd St                   
    ##  5 Broadway Jamaica 104th St-102nd St          
    ##  6 Liberty          104th St-Oxford Av         
    ##  7 Lexington        110th St                   
    ##  8 Lenox            110th St-Central Park North
    ##  9 Broadway Jamaica 111th St                   
    ## 10 Flushing         111th St                   
    ## # … with 455 more rows

Arranging the data by station name, we can see the output gave us
entries for each unique combination of station name and line.

In total, there are **465 unique stations**.

Next, we want to know how many stations are ADA-compliant. For this, we
can use `group_by` and `summarise` to get the frequency of `TRUE`’s
under the `ada` variable.

``` r
transit_data %>%
  distinct(line, station_name, .keep_all = TRUE) %>% 
  group_by(ada) %>%
  summarise(n = n())
```

    ## # A tibble: 2 × 2
    ##   ada       n
    ##   <lgl> <int>
    ## 1 FALSE   381
    ## 2 TRUE     84

From our results, we can see that **84 stations are ADA-compliant.**

Next, we want to know what proportion of entrances/exits without vending
allow entrance. For this, we will `filter` observations to those with
`vending == "NO"`, then use `group_by`, `summarise`, and `mutate` to
compute the proportion of entrances/exits with `entry == "YES"`.

``` r
transit_data %>%
  filter(vending == "NO") %>% 
  group_by(entry) %>%
  summarise(n = n()) %>%
  mutate(prop = n / sum(n))
```

    ## # A tibble: 2 × 3
    ##   entry     n  prop
    ##   <lgl> <int> <dbl>
    ## 1 FALSE   114 0.623
    ## 2 TRUE     69 0.377

From our results, **37.71% of station entrances / exits without vending
allow entry.**

Finally, we want to know how many stations serve the A and are
ADA-compliant. We will use `pivot_longer` to reformat data so that route
number and route name are distinct variables. To do this, we must first
mutate all `route#` variables into a character format so `pivot_longer`
can be used.

Then, we will filter the dataset to only stations that serve
`route_name == "A"`, and use `distinct` to get a list of unique
stations.

``` r
A_stations = transit_data %>% 
  mutate(route8 = as.character(route8), 
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11)) %>% 
  pivot_longer(
    route1:route11, 
    names_to = "route_number", 
    values_to = "route_name", 
    names_prefix = "route"
  ) %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name, .keep_all = TRUE)

A_stations
```

    ## # A tibble: 60 × 10
    ##    line      stati…¹ stati…² stati…³ entra…⁴ entry vending ada   route…⁵ route…⁶
    ##    <chr>     <chr>     <dbl>   <dbl> <chr>   <lgl> <chr>   <lgl> <chr>   <chr>  
    ##  1 42nd St … Times …    40.8   -74.0 Stair   TRUE  YES     FALSE 1       A      
    ##  2 8 Avenue  125th …    40.8   -74.0 Stair   TRUE  YES     FALSE 1       A      
    ##  3 8 Avenue  145th …    40.8   -73.9 Stair   TRUE  YES     FALSE 1       A      
    ##  4 8 Avenue  14th St    40.7   -74.0 Easeme… TRUE  YES     TRUE  1       A      
    ##  5 8 Avenue  168th …    40.8   -73.9 Stair   TRUE  YES     TRUE  1       A      
    ##  6 8 Avenue  175th …    40.8   -73.9 Elevat… TRUE  YES     TRUE  1       A      
    ##  7 8 Avenue  181st …    40.9   -73.9 Door    TRUE  YES     FALSE 1       A      
    ##  8 8 Avenue  190th …    40.9   -73.9 Door    TRUE  YES     FALSE 1       A      
    ##  9 8 Avenue  34th St    40.8   -74.0 Elevat… TRUE  YES     TRUE  1       A      
    ## 10 8 Avenue  42nd St    40.8   -74.0 Easeme… TRUE  YES     TRUE  1       A      
    ## # … with 50 more rows, and abbreviated variable names ¹​station_name,
    ## #   ²​station_latitude, ³​station_longitude, ⁴​entrance_type, ⁵​route_number,
    ## #   ⁶​route_name

We can see that there are 10 variables and 60 observations in our
A_stations dataset, indicating **60** unique stations that serve the A
line.

``` r
A_stations %>% 
  group_by(ada) %>% 
  summarise(n = n()) %>%
  mutate(prop = n / sum(n))
```

    ## # A tibble: 2 × 3
    ##   ada       n  prop
    ##   <lgl> <int> <dbl>
    ## 1 FALSE    43 0.717
    ## 2 TRUE     17 0.283

Finally, grouping the `A_stations` dataset by `ada` status, and
summarizing the results, we can see that **17 of the 60 (28.3%) stations
that serve the A are ADA-compliant.**

## Problem 2: Mr. Trash Wheel Data

### Reading and cleaning data

First, we will read and clean the Mr. Trash Wheel sheet from the Trash
Wheel Collection Totals Excel file in `./data` folder. We will convert
variable names to snake case, filter out observations without a dumpster
number (to remove rows without dumpster-specific data), round the
`sports_balls` variable to an integer, and add a `vessel` variable to
label all observations in the data as coming from Mr. Trash Wheel sheet.

``` r
mrtrash_wheel = 
  readxl::read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
                     sheet = "Mr. Trash Wheel",
                     range = "A2:N534") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(sports_balls)) %>% 
  mutate(vessel = "Mr. Trash Wheel")
```

Next, we will repeat the same reading and cleaning processes in the
Professor Trash Wheel sheet, in the same Excel file. Similarly, we will
add a `vessel` variable to label all observations in the data as coming
from Professor Trash Wheel sheet.

``` r
proftrash_wheel = 
  readxl::read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
                     sheet = "Professor Trash Wheel",
                     range = "A2:N116") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(sports_balls)) %>% 
  mutate(vessel = "Professor Trash Wheel")
```

Finally, we can bind the Mr. Trash Wheel and Professor Trash Wheel data
into a single tidy dataset. We can distinguish which observation comes
from which sheet using the `vessel` variable in column 1.

``` r
trash_wheel = 
  bind_rows(mrtrash_wheel, proftrash_wheel) %>% 
  relocate(vessel)
```

### Describing the `trash_wheel` dataset

``` r
trash_wheel
```

    ## # A tibble: 524 × 15
    ##    vessel        dumps…¹ month  year date                weigh…² volum…³ plast…⁴
    ##    <chr>           <dbl> <chr> <dbl> <dttm>                <dbl>   <dbl>   <dbl>
    ##  1 Mr. Trash Wh…       1 May    2014 2014-05-16 00:00:00    4.31      18    1450
    ##  2 Mr. Trash Wh…       2 May    2014 2014-05-16 00:00:00    2.74      13    1120
    ##  3 Mr. Trash Wh…       3 May    2014 2014-05-16 00:00:00    3.45      15    2450
    ##  4 Mr. Trash Wh…       4 May    2014 2014-05-17 00:00:00    3.1       15    2380
    ##  5 Mr. Trash Wh…       5 May    2014 2014-05-17 00:00:00    4.06      18     980
    ##  6 Mr. Trash Wh…       6 May    2014 2014-05-20 00:00:00    2.71      13    1430
    ##  7 Mr. Trash Wh…       7 May    2014 2014-05-21 00:00:00    1.91       8     910
    ##  8 Mr. Trash Wh…       8 May    2014 2014-05-28 00:00:00    3.7       16    3580
    ##  9 Mr. Trash Wh…       9 June   2014 2014-06-05 00:00:00    2.52      14    2400
    ## 10 Mr. Trash Wh…      10 June   2014 2014-06-11 00:00:00    3.76      18    1340
    ## # … with 514 more rows, 7 more variables: polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, grocery_bags <dbl>,
    ## #   chip_bags <dbl>, sports_balls <int>, homes_powered <dbl>, and abbreviated
    ## #   variable names ¹​dumpster, ²​weight_tons, ³​volume_cubic_yards,
    ## #   ⁴​plastic_bottles

In our tidied dataset, we have a tibble containing 15 variables and 524
observations. The variables in the dataset describe several
characteristics of each dumpster collected from either the Mr. Trash or
Professor Trash Wheel. It includes identifiers like the dumpster number
and date, and vessel it originates from. It also describes the weight
(in tons) and volume (in cubic yards) of trash collected, as well as
counts of common types of trash found in the dumpster, such as plastic
bottles, polystyrene, cigarette butts, and sports balls.

Using `summarise`, we can answer some questions about our data.

``` r
total_weight = trash_wheel %>% 
  filter(vessel == "Professor Trash Wheel") %>% 
  summarise(n = sum(weight_tons))

total_sports_balls = trash_wheel %>% 
  filter(vessel == "Mr. Trash Wheel", year == 2020) %>% 
  summarise(n = sum(sports_balls))
```

The total weight of trash collected by Professor Trash Wheel is **135.5
tons.**

The total number of sports balls collected by Mr. Trash Wheel in 2020
was **856.**

## Problem 3: FiveThirtyEight Data

### Reading and cleaning data

First, we will clean the `pols-month.csv` data.

We’ll use `separate()` to break up the variable `mon` into integer
variables year, month, and day. Then, we use `month.name` within the
`mutate` function to replace month number with month name. Then, we’ll
use `ifelse` to create a president variable taking values `gop` and
`dem`, and use `select` to remove `prez_dem`, `prez_gop`, and the `day`
variable.

``` r
pols_month = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(month = month.name[as.numeric(month)]) %>%
  mutate(year = as.numeric(year)) %>% 
  mutate(president = ifelse(prez_dem == 1, "dem", "rep")) %>% 
  select(-prez_dem, -prez_gop, -day)
```

Second, we will clean the data in `snp.csv` using a similar process as
above.

``` r
snp = read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), sep = "/") %>% 
  mutate(month = month.name[as.numeric(month)]) %>% 
  mutate(year = as.numeric(ifelse(year > 15, paste0("19", year), paste0("20", year)))) %>% 
  select(-day) %>% 
  relocate(year)
```

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemployment = read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "pct_unemployed") %>% 
  mutate(month = month.name[match(str_to_title(month), month.abb)])
```

Finally, we will join the datasets by merging `snp` into `pols`, and
merging unemployment into the final dataset, `five_thirty_eight`.

``` r
five_thirty_eight = 
  left_join(pols_month, snp, by = c("month", "year")) %>% 
  left_join(unemployment, by = c("month", "year"))
```

The dataset `pols-month` contains 822 observations of 9 variables
related to the number of national politicians who are democratic or
republican for each month between January 1947 and June 2015. It
includes counts of Democratic or Republican governors, Senators, and
Congressional representatives, as well as `president`, which indicates
whether the President at the time was Democratic or Republican.

The dataset `snp` contains 787 observations of 3 variables. Its main
variable is `closing`, which is the closing price of Standard & Poor’s
stock market index (S&P), often used as a representative measure of
stock market as a whole, for each month between January 1950 and July
2015.

The dataset `unemployment` contains 816 observations of 3 variables. Its
main variable is `pct_unemployed`, which is the unemployment rate for
each month between January 1948 and December 2015.

Joined together, the final `five_thirty_eight` dataset merges
information from the 3 prior datasets in a table of 11 variables and 822
observations. It contains information about the counts of national
politicians along party lines, closing prices of the S&P index, and
unemployment rate for each month between 1947 and 2015.
